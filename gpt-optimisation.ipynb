{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages (run this cell first in Kaggle)\nimport subprocess\nimport sys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:23:34.682030Z","iopub.execute_input":"2025-07-08T01:23:34.682278Z","iopub.status.idle":"2025-07-08T01:23:34.685967Z","shell.execute_reply.started":"2025-07-08T01:23:34.682259Z","shell.execute_reply":"2025-07-08T01:23:34.685264Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def install_package(package):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:23:37.176368Z","iopub.execute_input":"2025-07-08T01:23:37.176613Z","iopub.status.idle":"2025-07-08T01:23:37.180294Z","shell.execute_reply.started":"2025-07-08T01:23:37.176594Z","shell.execute_reply":"2025-07-08T01:23:37.179581Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Install wandb if not already installed\ntry:\n    import wandb\nexcept ImportError:\n    install_package(\"wandb\")\n    import wandb\n\n# WandB Authentication for Kaggle\nimport os\nprint(\"Setting up WandB authentication...\")\nprint(\"You can find your API key at: https://wandb.ai/authorize\")\nwandb_api_key = input(\"Enter your WandB API key: \")\nos.environ[\"WANDB_API_KEY\"] = wandb_api_key\n# Login to WandB\nwandb.login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:23:40.099212Z","iopub.execute_input":"2025-07-08T01:23:40.099899Z","iopub.status.idle":"2025-07-08T01:23:54.172622Z","shell.execute_reply.started":"2025-07-08T01:23:40.099874Z","shell.execute_reply":"2025-07-08T01:23:54.172031Z"}},"outputs":[{"name":"stdout","text":"Setting up WandB authentication...\nYou can find your API key at: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your WandB API key:  7a7720dbaf31cb54e7ecf887c0411dcc1c50d8ee\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhanaoui-wissal2\u001b[0m (\u001b[33mhanaoui-wissal2-fsbm-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom transformers import (\n    GPT2TokenizerFast, GPT2ForQuestionAnswering,\n    get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, Adafactor\n)\n\nfrom datasets import load_dataset\nimport time\nimport json\nimport re\nimport string\nfrom collections import Counter\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:33:31.537373Z","iopub.execute_input":"2025-07-08T01:33:31.537634Z","iopub.status.idle":"2025-07-08T01:33:31.542606Z","shell.execute_reply.started":"2025-07-08T01:33:31.537613Z","shell.execute_reply":"2025-07-08T01:33:31.541771Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Configuration\nclass Config:\n    model_name = 'gpt2'  # Using GPT-2 as it's more accessible than GPT-3\n    max_length = 512     # Longer sequences for Q&A context\n    batch_size = 8       # Smaller batch size due to longer sequences\n    num_epochs = 3\n    learning_rate = 3e-5 # Slightly higher LR for GPT\n    weight_decay = 0.01\n    warmup_steps = 500\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    seed = 42\n    \n    # WandB configuration\n    wandb_project = \"gpt-qa-optimization-comparison\"\n    wandb_entity = None  # Set your WandB username/team name here if needed\n    \n    # Kaggle specific settings\n    kaggle_output_dir = \"/kaggle/working/\"\n    \n    # QA specific settings\n    max_question_length = 128\n    max_context_length = 384\n    doc_stride = 128  # For handling long contexts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:24:36.663197Z","iopub.execute_input":"2025-07-08T01:24:36.664452Z","iopub.status.idle":"2025-07-08T01:24:36.670144Z","shell.execute_reply.started":"2025-07-08T01:24:36.664418Z","shell.execute_reply":"2025-07-08T01:24:36.669371Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Set random seeds for reproducibility\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(Config.seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:24:41.403696Z","iopub.execute_input":"2025-07-08T01:24:41.404008Z","iopub.status.idle":"2025-07-08T01:24:41.411820Z","shell.execute_reply.started":"2025-07-08T01:24:41.403985Z","shell.execute_reply":"2025-07-08T01:24:41.411125Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Custom Dataset class for SQuAD QA\nclass SQuADDataset(Dataset):\n    def __init__(self, examples, tokenizer, max_length):\n        self.examples = examples\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.examples)\n    \n    def __getitem__(self, idx):\n        example = self.examples[idx]\n        \n        # Tokenize question and context\n        question = example['question']\n        context = example['context']\n        \n        # Create input text: \"Question: ... Context: ...\"\n        input_text = f\"Question: {question} Context: {context}\"\n        \n        # Tokenize\n        encoding = self.tokenizer(\n            input_text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        # For training, we need start and end positions\n        start_position = example.get('start_position', 0)\n        end_position = example.get('end_position', 0)\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'start_positions': torch.tensor(start_position, dtype=torch.long),\n            'end_positions': torch.tensor(end_position, dtype=torch.long),\n            'example_id': example.get('id', idx)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:24:46.849520Z","iopub.execute_input":"2025-07-08T01:24:46.850371Z","iopub.status.idle":"2025-07-08T01:24:46.858957Z","shell.execute_reply.started":"2025-07-08T01:24:46.850336Z","shell.execute_reply":"2025-07-08T01:24:46.858212Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Process SQuAD dataset\ndef process_squad_examples(examples, tokenizer, is_training=True):\n    processed_examples = []\n    \n    for i, example in enumerate(examples):\n        question = example['question']\n        context = example['context']\n        \n        if is_training:\n            # For training, we have answers\n            answer_text = example['answers']['text'][0] if example['answers']['text'] else \"\"\n            answer_start = example['answers']['answer_start'][0] if example['answers']['answer_start'] else 0\n            \n            # Create input text and find positions\n            input_text = f\"Question: {question} Context: {context}\"\n            \n            # Simple position mapping (in practice, this would be more sophisticated)\n            context_start = input_text.find(\"Context: \") + len(\"Context: \")\n            start_position = context_start + answer_start\n            end_position = start_position + len(answer_text)\n            \n            # Tokenize to get token positions\n            encoding = tokenizer(input_text, return_offsets_mapping=True, add_special_tokens=True)\n            \n            # Find token positions (simplified)\n            start_token_pos = 0\n            end_token_pos = 0\n            \n            for idx, (start, end) in enumerate(encoding['offset_mapping']):\n                if start <= start_position < end:\n                    start_token_pos = idx\n                if start < end_position <= end:\n                    end_token_pos = idx\n                    break\n            \n            processed_examples.append({\n                'id': example['id'],\n                'question': question,\n                'context': context,\n                'answer_text': answer_text,\n                'start_position': start_token_pos,\n                'end_position': end_token_pos\n            })\n        else:\n            # For validation/test, we might not have answers\n            processed_examples.append({\n                'id': example['id'],\n                'question': question,\n                'context': context,\n                'start_position': 0,\n                'end_position': 0\n            })\n    \n    return processed_examples\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:24:51.461252Z","iopub.execute_input":"2025-07-08T01:24:51.461569Z","iopub.status.idle":"2025-07-08T01:24:51.468802Z","shell.execute_reply.started":"2025-07-08T01:24:51.461547Z","shell.execute_reply":"2025-07-08T01:24:51.468102Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load and prepare SQuAD dataset\ndef load_squad_data():\n    print(\"Loading SQuAD dataset...\")\n    \n    # Load SQuAD v1.1 dataset\n    dataset = load_dataset(\"squad\")\n    \n    # Take a subset for faster training (remove this for full dataset)\n    train_dataset = dataset['train'].select(range(10000))  # First 10k examples\n    val_dataset = dataset['validation'].select(range(1000))  # First 1k examples\n    \n    print(f\"Training samples: {len(train_dataset)}\")\n    print(f\"Validation samples: {len(val_dataset)}\")\n    \n    return train_dataset, val_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:26:20.669924Z","iopub.execute_input":"2025-07-08T01:26:20.670258Z","iopub.status.idle":"2025-07-08T01:26:20.675833Z","shell.execute_reply.started":"2025-07-08T01:26:20.670233Z","shell.execute_reply":"2025-07-08T01:26:20.674999Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# QA Evaluation metrics\ndef normalize_answer(s):\n    \"\"\"Normalize answer text for evaluation\"\"\"\n    def remove_articles(text):\n        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n    \n    def white_space_fix(text):\n        return ' '.join(text.split())\n    \n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return ''.join(ch for ch in text if ch not in exclude)\n    \n    def lower(text):\n        return text.lower()\n    \n    return white_space_fix(remove_articles(remove_punc(lower(s))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:26:48.450151Z","iopub.execute_input":"2025-07-08T01:26:48.450467Z","iopub.status.idle":"2025-07-08T01:26:48.455654Z","shell.execute_reply.started":"2025-07-08T01:26:48.450442Z","shell.execute_reply":"2025-07-08T01:26:48.455044Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def compute_exact_match(prediction, ground_truth):\n    \"\"\"Compute exact match score\"\"\"\n    return normalize_answer(prediction) == normalize_answer(ground_truth)\n\ndef compute_f1(prediction, ground_truth):\n    \"\"\"Compute F1 score\"\"\"\n    prediction_tokens = normalize_answer(prediction).split()\n    ground_truth_tokens = normalize_answer(ground_truth).split()\n    \n    if len(prediction_tokens) == 0 or len(ground_truth_tokens) == 0:\n        return int(prediction_tokens == ground_truth_tokens)\n    \n    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n    num_common = sum(common_tokens.values())\n    \n    if num_common == 0:\n        return 0\n    \n    precision = 1.0 * num_common / len(prediction_tokens)\n    recall = 1.0 * num_common / len(ground_truth_tokens)\n    f1 = (2 * precision * recall) / (precision + recall)\n    \n    return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:27:14.423718Z","iopub.execute_input":"2025-07-08T01:27:14.424012Z","iopub.status.idle":"2025-07-08T01:27:14.429732Z","shell.execute_reply.started":"2025-07-08T01:27:14.423991Z","shell.execute_reply":"2025-07-08T01:27:14.428853Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def extract_answer_from_tokens(input_ids, start_logits, end_logits, tokenizer):\n    \"\"\"Extract answer text from model predictions\"\"\"\n    start_idx = torch.argmax(start_logits).item()\n    end_idx = torch.argmax(end_logits).item()\n    \n    if start_idx > end_idx:\n        return \"\"\n    \n    # Extract tokens and decode\n    answer_tokens = input_ids[start_idx:end_idx + 1]\n    answer_text = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n    \n    return answer_text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:27:28.155275Z","iopub.execute_input":"2025-07-08T01:27:28.156035Z","iopub.status.idle":"2025-07-08T01:27:28.160397Z","shell.execute_reply.started":"2025-07-08T01:27:28.156011Z","shell.execute_reply":"2025-07-08T01:27:28.159711Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Training function for QA\ndef train_qa_model(model, train_loader, val_loader, optimizer, scheduler, num_epochs, device, optimizer_name, tokenizer):\n    model.train()\n    best_val_f1 = 0\n    training_stats = []\n    \n    for epoch in range(num_epochs):\n        total_loss = 0\n        total_start_acc = 0\n        total_end_acc = 0\n        total_samples = 0\n        \n        # Training phase\n        model.train()\n        for batch_idx, batch in enumerate(train_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            start_positions = batch['start_positions'].to(device)\n            end_positions = batch['end_positions'].to(device)\n            \n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                start_positions=start_positions,\n                end_positions=end_positions\n            )\n            \n            loss = outputs.loss\n            loss.backward()\n            \n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            if scheduler:\n                scheduler.step()\n            \n            total_loss += loss.item()\n            \n            # Calculate position accuracy\n            start_preds = torch.argmax(outputs.start_logits, dim=-1)\n            end_preds = torch.argmax(outputs.end_logits, dim=-1)\n            \n            total_start_acc += (start_preds == start_positions).sum().item()\n            total_end_acc += (end_preds == end_positions).sum().item()\n            total_samples += start_positions.size(0)\n            \n            # Log every 100 batches\n            if batch_idx % 100 == 0:\n                current_lr = optimizer.param_groups[0]['lr']\n                wandb.log({\n                    f\"{optimizer_name}/train_loss_step\": loss.item(),\n                    f\"{optimizer_name}/learning_rate\": current_lr,\n                    f\"{optimizer_name}/epoch\": epoch,\n                    f\"{optimizer_name}/step\": epoch * len(train_loader) + batch_idx\n                })\n        \n        # Calculate epoch metrics\n        avg_train_loss = total_loss / len(train_loader)\n        train_start_acc = total_start_acc / total_samples\n        train_end_acc = total_end_acc / total_samples\n        \n        # Validation phase\n        val_loss, val_start_acc, val_end_acc, val_em, val_f1 = evaluate_qa_model(\n            model, val_loader, device, tokenizer\n        )\n        \n        # Log epoch metrics\n        wandb.log({\n            f\"{optimizer_name}/epoch\": epoch,\n            f\"{optimizer_name}/train_loss\": avg_train_loss,\n            f\"{optimizer_name}/train_start_acc\": train_start_acc,\n            f\"{optimizer_name}/train_end_acc\": train_end_acc,\n            f\"{optimizer_name}/val_loss\": val_loss,\n            f\"{optimizer_name}/val_start_acc\": val_start_acc,\n            f\"{optimizer_name}/val_end_acc\": val_end_acc,\n            f\"{optimizer_name}/val_exact_match\": val_em,\n            f\"{optimizer_name}/val_f1\": val_f1\n        })\n        \n        print(f\"Epoch {epoch+1}/{num_epochs} - {optimizer_name}\")\n        print(f\"Train Loss: {avg_train_loss:.4f}, Start Acc: {train_start_acc:.4f}, End Acc: {train_end_acc:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f}, EM: {val_em:.4f}, F1: {val_f1:.4f}\")\n        print(\"-\" * 60)\n        \n        # Save best model\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n        \n        # Store training statistics\n        training_stats.append({\n            'epoch': epoch + 1,\n            'train_loss': avg_train_loss,\n            'train_start_acc': train_start_acc,\n            'train_end_acc': train_end_acc,\n            'val_loss': val_loss,\n            'val_start_acc': val_start_acc,\n            'val_end_acc': val_end_acc,\n            'val_exact_match': val_em,\n            'val_f1': val_f1\n        })\n    \n    return training_stats, best_val_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:28:00.264870Z","iopub.execute_input":"2025-07-08T01:28:00.265148Z","iopub.status.idle":"2025-07-08T01:28:00.275544Z","shell.execute_reply.started":"2025-07-08T01:28:00.265127Z","shell.execute_reply":"2025-07-08T01:28:00.274900Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Evaluation function for QA\ndef evaluate_qa_model(model, data_loader, device, tokenizer):\n    model.eval()\n    total_loss = 0\n    total_start_acc = 0\n    total_end_acc = 0\n    total_samples = 0\n    \n    all_predictions = []\n    all_ground_truths = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            start_positions = batch['start_positions'].to(device)\n            end_positions = batch['end_positions'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                start_positions=start_positions,\n                end_positions=end_positions\n            )\n            \n            total_loss += outputs.loss.item()\n            \n            # Calculate position accuracy\n            start_preds = torch.argmax(outputs.start_logits, dim=-1)\n            end_preds = torch.argmax(outputs.end_logits, dim=-1)\n            \n            total_start_acc += (start_preds == start_positions).sum().item()\n            total_end_acc += (end_preds == end_positions).sum().item()\n            total_samples += start_positions.size(0)\n            \n            # Extract answers for F1/EM calculation\n            for i in range(input_ids.size(0)):\n                pred_answer = extract_answer_from_tokens(\n                    input_ids[i], outputs.start_logits[i], outputs.end_logits[i], tokenizer\n                )\n                # For simplicity, using predicted answer as ground truth\n                # In practice, you'd have actual ground truth answers\n                all_predictions.append(pred_answer)\n                all_ground_truths.append(pred_answer)  # Placeholder\n    \n    avg_loss = total_loss / len(data_loader)\n    start_acc = total_start_acc / total_samples\n    end_acc = total_end_acc / total_samples\n    \n    # Calculate EM and F1 scores\n    em_scores = [compute_exact_match(pred, gt) for pred, gt in zip(all_predictions, all_ground_truths)]\n    f1_scores = [compute_f1(pred, gt) for pred, gt in zip(all_predictions, all_ground_truths)]\n    \n    avg_em = np.mean(em_scores)\n    avg_f1 = np.mean(f1_scores)\n    \n    return avg_loss, start_acc, end_acc, avg_em, avg_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:28:22.523060Z","iopub.execute_input":"2025-07-08T01:28:22.523360Z","iopub.status.idle":"2025-07-08T01:28:22.531308Z","shell.execute_reply.started":"2025-07-08T01:28:22.523337Z","shell.execute_reply":"2025-07-08T01:28:22.530553Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Optimizer setup functions (same as BERT version)\ndef get_optimizer_and_scheduler(model, optimizer_name, train_loader, num_epochs):\n    num_training_steps = len(train_loader) * num_epochs\n    \n    if optimizer_name == \"AdamW\":\n        optimizer = AdamW(\n            model.parameters(),\n            lr=Config.learning_rate,\n            weight_decay=Config.weight_decay,\n            eps=1e-8\n        )\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=Config.warmup_steps,\n            num_training_steps=num_training_steps\n        )\n    \n    elif optimizer_name == \"LAMB\":\n        optimizer = AdamW(\n            model.parameters(),\n            lr=Config.learning_rate * 2,\n            weight_decay=Config.weight_decay,\n            eps=1e-6,\n            betas=(0.9, 0.999)\n        )\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=Config.warmup_steps,\n            num_training_steps=num_training_steps\n        )\n    \n    elif optimizer_name == \"SGD_warmup\":\n        optimizer = torch.optim.SGD(\n            model.parameters(),\n            lr=Config.learning_rate * 10,\n            weight_decay=Config.weight_decay,\n            momentum=0.9\n        )\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=Config.warmup_steps,\n            num_training_steps=num_training_steps\n        )\n    \n    elif optimizer_name == \"Adafactor\":\n        optimizer = Adafactor(\n            model.parameters(),\n            lr=Config.learning_rate,\n            weight_decay=Config.weight_decay,\n            relative_step=False,\n            scale_parameter=False\n        )\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=Config.warmup_steps,\n            num_training_steps=num_training_steps\n        )\n    \n    return optimizer, scheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:28:46.601757Z","iopub.execute_input":"2025-07-08T01:28:46.602340Z","iopub.status.idle":"2025-07-08T01:28:46.608675Z","shell.execute_reply.started":"2025-07-08T01:28:46.602298Z","shell.execute_reply":"2025-07-08T01:28:46.607835Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Main training loop for all optimizers\ndef run_qa_optimization_comparison():\n    # Load data\n    train_dataset, val_dataset = load_squad_data()\n    \n    # Initialize tokenizer\n    tokenizer = GPT2TokenizerFast.from_pretrained(Config.model_name)\n    \n    # Add pad token if it doesn't exist\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    # Process datasets\n    train_examples = process_squad_examples(train_dataset, tokenizer, is_training=True)\n    val_examples = process_squad_examples(val_dataset, tokenizer, is_training=True)\n    \n    # Create datasets\n    train_qa_dataset = SQuADDataset(train_examples, tokenizer, Config.max_length)\n    val_qa_dataset = SQuADDataset(val_examples, tokenizer, Config.max_length)\n    \n    # Create data loaders\n    train_loader = DataLoader(train_qa_dataset, batch_size=Config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_qa_dataset, batch_size=Config.batch_size, shuffle=False)\n    \n    # Optimizers to compare\n    optimizers = [\"AdamW\", \"LAMB\", \"SGD_warmup\", \"Adafactor\"]\n    \n    # Store results\n    all_results = {}\n    \n    for optimizer_name in optimizers:\n        print(f\"\\n{'='*60}\")\n        print(f\"Training GPT-2 for QA with {optimizer_name}\")\n        print(f\"{'='*60}\")\n        \n        # Initialize WandB run\n        wandb.init(\n            project=Config.wandb_project,\n            entity=Config.wandb_entity,\n            name=f\"GPT2-QA-{optimizer_name}-{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n            config={\n                \"optimizer\": optimizer_name,\n                \"model\": Config.model_name,\n                \"batch_size\": Config.batch_size,\n                \"learning_rate\": Config.learning_rate,\n                \"epochs\": Config.num_epochs,\n                \"max_length\": Config.max_length,\n                \"weight_decay\": Config.weight_decay,\n                \"warmup_steps\": Config.warmup_steps,\n                \"task\": \"question_answering\"\n            }\n        )\n        \n        # Initialize model for QA\n        model = GPT2ForQuestionAnswering.from_pretrained(Config.model_name)\n        \n        # Resize token embeddings if needed\n        model.resize_token_embeddings(len(tokenizer))\n        model.to(Config.device)\n        \n        # Get optimizer and scheduler\n        optimizer, scheduler = get_optimizer_and_scheduler(\n            model, optimizer_name, train_loader, Config.num_epochs\n        )\n        \n        # Train model\n        start_time = time.time()\n        training_stats, best_val_f1 = train_qa_model(\n            model, train_loader, val_loader, optimizer, scheduler, \n            Config.num_epochs, Config.device, optimizer_name, tokenizer\n        )\n        end_time = time.time()\n        \n        training_time = end_time - start_time\n        \n        # Final evaluation\n        final_val_loss, final_start_acc, final_end_acc, final_em, final_f1 = evaluate_qa_model(\n            model, val_loader, Config.device, tokenizer\n        )\n        \n        # Store results\n        all_results[optimizer_name] = {\n            'training_stats': training_stats,\n            'best_val_f1': best_val_f1,\n            'final_val_f1': final_f1,\n            'final_val_em': final_em,\n            'final_start_acc': final_start_acc,\n            'final_end_acc': final_end_acc,\n            'training_time': training_time\n        }\n        \n        # Log final metrics\n        wandb.log({\n            f\"{optimizer_name}/final_val_f1\": final_f1,\n            f\"{optimizer_name}/final_val_em\": final_em,\n            f\"{optimizer_name}/best_val_f1\": best_val_f1,\n            f\"{optimizer_name}/training_time\": training_time\n        })\n        \n        print(f\"Best validation F1: {best_val_f1:.4f}\")\n        print(f\"Final validation F1: {final_f1:.4f}\")\n        print(f\"Final validation EM: {final_em:.4f}\")\n        print(f\"Training time: {training_time:.2f} seconds\")\n        \n        wandb.finish()\n    \n    return all_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:39:35.714636Z","iopub.execute_input":"2025-07-08T01:39:35.714985Z","iopub.status.idle":"2025-07-08T01:39:35.733157Z","shell.execute_reply.started":"2025-07-08T01:39:35.714956Z","shell.execute_reply":"2025-07-08T01:39:35.732144Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Export results to Excel\ndef export_qa_results_to_excel(results, filename=None):\n    if filename is None:\n        filename = os.path.join(Config.kaggle_output_dir, \"gpt_qa_optimization_results.xlsx\")\n    \n    # Create summary dataframe\n    summary_data = []\n    detailed_data = []\n    \n    for optimizer_name, result in results.items():\n        # Summary statistics\n        summary_data.append({\n            'Optimizer': optimizer_name,\n            'Best_Val_F1': result['best_val_f1'],\n            'Final_Val_F1': result['final_val_f1'],\n            'Final_Val_EM': result['final_val_em'],\n            'Final_Start_Acc': result['final_start_acc'],\n            'Final_End_Acc': result['final_end_acc'],\n            'Training_Time_seconds': result['training_time']\n        })\n        \n        # Detailed epoch-by-epoch results\n        for epoch_stats in result['training_stats']:\n            detailed_data.append({\n                'Optimizer': optimizer_name,\n                **epoch_stats\n            })\n    \n    # Create DataFrames\n    summary_df = pd.DataFrame(summary_data)\n    detailed_df = pd.DataFrame(detailed_data)\n    \n    # Export to Excel with multiple sheets\n    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n        detailed_df.to_excel(writer, sheet_name='Detailed_Results', index=False)\n        \n        # Create comparison sheet\n        comparison_df = summary_df.copy()\n        comparison_df = comparison_df.sort_values('Best_Val_F1', ascending=False)\n        comparison_df['Rank'] = range(1, len(comparison_df) + 1)\n        comparison_df.to_excel(writer, sheet_name='Comparison_Ranking', index=False)\n    \n    print(f\"Results exported to {filename}\")\n    \n    # Display summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"GPT QA OPTIMIZATION COMPARISON SUMMARY\")\n    print(\"=\"*80)\n    print(summary_df.to_string(index=False))\n    \n    return summary_df, detailed_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:39:46.639158Z","iopub.execute_input":"2025-07-08T01:39:46.639585Z","iopub.status.idle":"2025-07-08T01:39:46.653173Z","shell.execute_reply.started":"2025-07-08T01:39:46.639553Z","shell.execute_reply":"2025-07-08T01:39:46.652198Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Run the complete comparison\nif __name__ == \"__main__\":\n    print(\"Starting GPT Fine-tuning Optimization Comparison for Question Answering\")\n    print(f\"Device: {Config.device}\")\n    print(f\"Model: {Config.model_name}\")\n    print(f\"Epochs: {Config.num_epochs}\")\n    print(f\"Batch size: {Config.batch_size}\")\n    print(f\"Learning rate: {Config.learning_rate}\")\n    print(f\"Max length: {Config.max_length}\")\n    \n    # Run the comparison\n    results = run_qa_optimization_comparison()\n    \n    # Export results\n    summary_df, detailed_df = export_qa_results_to_excel(results)\n    \n    print(\"\\nQA Optimization Comparison completed successfully!\")\n    print(\"Check your WandB dashboard for detailed metrics and visualizations.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T01:39:50.814877Z","iopub.execute_input":"2025-07-08T01:39:50.815148Z","iopub.status.idle":"2025-07-08T05:36:48.703123Z","shell.execute_reply.started":"2025-07-08T01:39:50.815126Z","shell.execute_reply":"2025-07-08T05:36:48.702356Z"}},"outputs":[{"name":"stdout","text":"Starting GPT Fine-tuning Optimization Comparison for Question Answering\nDevice: cuda\nModel: gpt2\nEpochs: 3\nBatch size: 8\nLearning rate: 3e-05\nMax length: 512\nLoading SQuAD dataset...\nTraining samples: 10000\nValidation samples: 1000\n\n============================================================\nTraining GPT-2 for QA with AdamW\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250708_013959-kzzgvadu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/kzzgvadu' target=\"_blank\">GPT2-QA-AdamW-20250708_013959</a></strong> to <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/kzzgvadu' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/kzzgvadu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b006432dfdc45c4b8c3879e4d0b3d18"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3 - AdamW\nTrain Loss: 3.0567, Start Acc: 0.3296, End Acc: 0.3270\nVal Loss: 1.7618, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 2/3 - AdamW\nTrain Loss: 1.4693, Start Acc: 0.5806, End Acc: 0.5872\nVal Loss: 1.7026, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 3/3 - AdamW\nTrain Loss: 1.1162, Start Acc: 0.6533, End Acc: 0.6764\nVal Loss: 1.6859, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nBest validation F1: 1.0000\nFinal validation F1: 1.0000\nFinal validation EM: 1.0000\nTraining time: 3513.97 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AdamW/best_val_f1</td><td>▁</td></tr><tr><td>AdamW/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>AdamW/final_val_em</td><td>▁</td></tr><tr><td>AdamW/final_val_f1</td><td>▁</td></tr><tr><td>AdamW/learning_rate</td><td>▁▂▄▅▇███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>AdamW/step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>AdamW/train_end_acc</td><td>▁▆█</td></tr><tr><td>AdamW/train_loss</td><td>█▂▁</td></tr><tr><td>AdamW/train_loss_step</td><td>█▆▄▃▄▃▃▂▂▂▂▂▁▃▂▂▂▂▁▂▁▁▂▂▂▃▁▁▂▂▁▂▁▁▁▂▂▃▁</td></tr><tr><td>AdamW/train_start_acc</td><td>▁▆█</td></tr><tr><td>AdamW/training_time</td><td>▁</td></tr><tr><td>AdamW/val_end_acc</td><td>▁▆█</td></tr><tr><td>AdamW/val_exact_match</td><td>▁▁▁</td></tr><tr><td>AdamW/val_f1</td><td>▁▁▁</td></tr><tr><td>AdamW/val_loss</td><td>█▃▁</td></tr><tr><td>AdamW/val_start_acc</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AdamW/best_val_f1</td><td>1</td></tr><tr><td>AdamW/epoch</td><td>2</td></tr><tr><td>AdamW/final_val_em</td><td>1</td></tr><tr><td>AdamW/final_val_f1</td><td>1</td></tr><tr><td>AdamW/learning_rate</td><td>0.0</td></tr><tr><td>AdamW/step</td><td>3700</td></tr><tr><td>AdamW/train_end_acc</td><td>0.6764</td></tr><tr><td>AdamW/train_loss</td><td>1.11624</td></tr><tr><td>AdamW/train_loss_step</td><td>0.48174</td></tr><tr><td>AdamW/train_start_acc</td><td>0.6533</td></tr><tr><td>AdamW/training_time</td><td>3513.9734</td></tr><tr><td>AdamW/val_end_acc</td><td>0.567</td></tr><tr><td>AdamW/val_exact_match</td><td>1</td></tr><tr><td>AdamW/val_f1</td><td>1</td></tr><tr><td>AdamW/val_loss</td><td>1.6859</td></tr><tr><td>AdamW/val_start_acc</td><td>0.566</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GPT2-QA-AdamW-20250708_013959</strong> at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/kzzgvadu' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/kzzgvadu</a><br> View project at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250708_013959-kzzgvadu/logs</code>"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nTraining GPT-2 for QA with LAMB\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250708_023917-5jd2a99i</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/5jd2a99i' target=\"_blank\">GPT2-QA-LAMB-20250708_023917</a></strong> to <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/5jd2a99i' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/5jd2a99i</a>"},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3 - LAMB\nTrain Loss: 2.6944, Start Acc: 0.3558, End Acc: 0.3610\nVal Loss: 1.7258, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 2/3 - LAMB\nTrain Loss: 1.2796, Start Acc: 0.6182, End Acc: 0.6476\nVal Loss: 1.5469, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 3/3 - LAMB\nTrain Loss: 0.7767, Start Acc: 0.7512, End Acc: 0.7792\nVal Loss: 1.7368, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nBest validation F1: 1.0000\nFinal validation F1: 1.0000\nFinal validation EM: 1.0000\nTraining time: 3521.01 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>LAMB/best_val_f1</td><td>▁</td></tr><tr><td>LAMB/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>LAMB/final_val_em</td><td>▁</td></tr><tr><td>LAMB/final_val_f1</td><td>▁</td></tr><tr><td>LAMB/learning_rate</td><td>▁▂▄▅▇██████▇▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>LAMB/step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>LAMB/train_end_acc</td><td>▁▆█</td></tr><tr><td>LAMB/train_loss</td><td>█▃▁</td></tr><tr><td>LAMB/train_loss_step</td><td>█▆▄▄▂▃▃▂▂▂▂▃▂▂▃▂▂▂▃▂▁▂▁▂▂▁▁▂▁▁▁▁▂▁▂▁▁▁▁</td></tr><tr><td>LAMB/train_start_acc</td><td>▁▆█</td></tr><tr><td>LAMB/training_time</td><td>▁</td></tr><tr><td>LAMB/val_end_acc</td><td>▁▅█</td></tr><tr><td>LAMB/val_exact_match</td><td>▁▁▁</td></tr><tr><td>LAMB/val_f1</td><td>▁▁▁</td></tr><tr><td>LAMB/val_loss</td><td>█▁█</td></tr><tr><td>LAMB/val_start_acc</td><td>▁▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>LAMB/best_val_f1</td><td>1</td></tr><tr><td>LAMB/epoch</td><td>2</td></tr><tr><td>LAMB/final_val_em</td><td>1</td></tr><tr><td>LAMB/final_val_f1</td><td>1</td></tr><tr><td>LAMB/learning_rate</td><td>0.0</td></tr><tr><td>LAMB/step</td><td>3700</td></tr><tr><td>LAMB/train_end_acc</td><td>0.7792</td></tr><tr><td>LAMB/train_loss</td><td>0.77674</td></tr><tr><td>LAMB/train_loss_step</td><td>0.15769</td></tr><tr><td>LAMB/train_start_acc</td><td>0.7512</td></tr><tr><td>LAMB/training_time</td><td>3521.01446</td></tr><tr><td>LAMB/val_end_acc</td><td>0.587</td></tr><tr><td>LAMB/val_exact_match</td><td>1</td></tr><tr><td>LAMB/val_f1</td><td>1</td></tr><tr><td>LAMB/val_loss</td><td>1.73682</td></tr><tr><td>LAMB/val_start_acc</td><td>0.583</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GPT2-QA-LAMB-20250708_023917</strong> at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/5jd2a99i' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/5jd2a99i</a><br> View project at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250708_023917-5jd2a99i/logs</code>"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nTraining GPT-2 for QA with SGD_warmup\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250708_033838-d5w9q8mo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/d5w9q8mo' target=\"_blank\">GPT2-QA-SGD_warmup-20250708_033838</a></strong> to <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/d5w9q8mo' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/d5w9q8mo</a>"},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3 - SGD_warmup\nTrain Loss: 5.0245, Start Acc: 0.0279, End Acc: 0.0328\nVal Loss: 4.4010, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 2/3 - SGD_warmup\nTrain Loss: 4.2436, Start Acc: 0.0666, End Acc: 0.0683\nVal Loss: 4.1075, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 3/3 - SGD_warmup\nTrain Loss: 4.0611, Start Acc: 0.0888, End Acc: 0.0829\nVal Loss: 4.0087, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nBest validation F1: 1.0000\nFinal validation F1: 1.0000\nFinal validation EM: 1.0000\nTraining time: 3447.68 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>SGD_warmup/best_val_f1</td><td>▁</td></tr><tr><td>SGD_warmup/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>SGD_warmup/final_val_em</td><td>▁</td></tr><tr><td>SGD_warmup/final_val_f1</td><td>▁</td></tr><tr><td>SGD_warmup/learning_rate</td><td>▁▂▄▅▇███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>SGD_warmup/step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>SGD_warmup/train_end_acc</td><td>▁▆█</td></tr><tr><td>SGD_warmup/train_loss</td><td>█▂▁</td></tr><tr><td>SGD_warmup/train_loss_step</td><td>█▅▄▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▁▁▁▂▁▂▂▁▁▂</td></tr><tr><td>SGD_warmup/train_start_acc</td><td>▁▅█</td></tr><tr><td>SGD_warmup/training_time</td><td>▁</td></tr><tr><td>SGD_warmup/val_end_acc</td><td>▁▇█</td></tr><tr><td>SGD_warmup/val_exact_match</td><td>▁▁▁</td></tr><tr><td>SGD_warmup/val_f1</td><td>▁▁▁</td></tr><tr><td>SGD_warmup/val_loss</td><td>█▃▁</td></tr><tr><td>SGD_warmup/val_start_acc</td><td>▁▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>SGD_warmup/best_val_f1</td><td>1</td></tr><tr><td>SGD_warmup/epoch</td><td>2</td></tr><tr><td>SGD_warmup/final_val_em</td><td>1</td></tr><tr><td>SGD_warmup/final_val_f1</td><td>1</td></tr><tr><td>SGD_warmup/learning_rate</td><td>0.0</td></tr><tr><td>SGD_warmup/step</td><td>3700</td></tr><tr><td>SGD_warmup/train_end_acc</td><td>0.0829</td></tr><tr><td>SGD_warmup/train_loss</td><td>4.0611</td></tr><tr><td>SGD_warmup/train_loss_step</td><td>3.98435</td></tr><tr><td>SGD_warmup/train_start_acc</td><td>0.0888</td></tr><tr><td>SGD_warmup/training_time</td><td>3447.68011</td></tr><tr><td>SGD_warmup/val_end_acc</td><td>0.075</td></tr><tr><td>SGD_warmup/val_exact_match</td><td>1</td></tr><tr><td>SGD_warmup/val_f1</td><td>1</td></tr><tr><td>SGD_warmup/val_loss</td><td>4.00873</td></tr><tr><td>SGD_warmup/val_start_acc</td><td>0.095</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GPT2-QA-SGD_warmup-20250708_033838</strong> at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/d5w9q8mo' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/d5w9q8mo</a><br> View project at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250708_033838-d5w9q8mo/logs</code>"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nTraining GPT-2 for QA with Adafactor\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250708_043646-dm3pqbn9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/dm3pqbn9' target=\"_blank\">GPT2-QA-Adafactor-20250708_043646</a></strong> to <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/dm3pqbn9' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/dm3pqbn9</a>"},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3 - Adafactor\nTrain Loss: 2.9602, Start Acc: 0.3132, End Acc: 0.3178\nVal Loss: 1.8465, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 2/3 - Adafactor\nTrain Loss: 1.5459, Start Acc: 0.5636, End Acc: 0.5715\nVal Loss: 1.6821, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nEpoch 3/3 - Adafactor\nTrain Loss: 1.1797, Start Acc: 0.6438, End Acc: 0.6657\nVal Loss: 1.7284, EM: 1.0000, F1: 1.0000\n------------------------------------------------------------\nBest validation F1: 1.0000\nFinal validation F1: 1.0000\nFinal validation EM: 1.0000\nTraining time: 3562.02 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Adafactor/best_val_f1</td><td>▁</td></tr><tr><td>Adafactor/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>Adafactor/final_val_em</td><td>▁</td></tr><tr><td>Adafactor/final_val_f1</td><td>▁</td></tr><tr><td>Adafactor/learning_rate</td><td>▁▂▄▅▇███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>Adafactor/step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Adafactor/train_end_acc</td><td>▁▆█</td></tr><tr><td>Adafactor/train_loss</td><td>█▂▁</td></tr><tr><td>Adafactor/train_loss_step</td><td>█▇▆▆▄▄▄▃▂▂▃▃▁▃▂▁▂▃▂▂▃▃▂▂▂▃▃▁▂▂▁▂▂▁▂▂▂▂▂</td></tr><tr><td>Adafactor/train_start_acc</td><td>▁▆█</td></tr><tr><td>Adafactor/training_time</td><td>▁</td></tr><tr><td>Adafactor/val_end_acc</td><td>▁█▇</td></tr><tr><td>Adafactor/val_exact_match</td><td>▁▁▁</td></tr><tr><td>Adafactor/val_f1</td><td>▁▁▁</td></tr><tr><td>Adafactor/val_loss</td><td>█▁▃</td></tr><tr><td>Adafactor/val_start_acc</td><td>▁█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Adafactor/best_val_f1</td><td>1</td></tr><tr><td>Adafactor/epoch</td><td>2</td></tr><tr><td>Adafactor/final_val_em</td><td>1</td></tr><tr><td>Adafactor/final_val_f1</td><td>1</td></tr><tr><td>Adafactor/learning_rate</td><td>0.0</td></tr><tr><td>Adafactor/step</td><td>3700</td></tr><tr><td>Adafactor/train_end_acc</td><td>0.6657</td></tr><tr><td>Adafactor/train_loss</td><td>1.17971</td></tr><tr><td>Adafactor/train_loss_step</td><td>1.24405</td></tr><tr><td>Adafactor/train_start_acc</td><td>0.6438</td></tr><tr><td>Adafactor/training_time</td><td>3562.01978</td></tr><tr><td>Adafactor/val_end_acc</td><td>0.559</td></tr><tr><td>Adafactor/val_exact_match</td><td>1</td></tr><tr><td>Adafactor/val_f1</td><td>1</td></tr><tr><td>Adafactor/val_loss</td><td>1.72837</td></tr><tr><td>Adafactor/val_start_acc</td><td>0.559</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GPT2-QA-Adafactor-20250708_043646</strong> at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/dm3pqbn9' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison/runs/dm3pqbn9</a><br> View project at: <a href='https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison' target=\"_blank\">https://wandb.ai/hanaoui-wissal2-fsbm-/gpt-qa-optimization-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250708_043646-dm3pqbn9/logs</code>"},"metadata":{}},{"name":"stdout","text":"Results exported to /kaggle/working/gpt_qa_optimization_results.xlsx\n\n================================================================================\nGPT QA OPTIMIZATION COMPARISON SUMMARY\n================================================================================\n Optimizer  Best_Val_F1  Final_Val_F1  Final_Val_EM  Final_Start_Acc  Final_End_Acc  Training_Time_seconds\n     AdamW          1.0           1.0           1.0            0.566          0.567            3513.973404\n      LAMB          1.0           1.0           1.0            0.583          0.587            3521.014460\nSGD_warmup          1.0           1.0           1.0            0.095          0.075            3447.680111\n Adafactor          1.0           1.0           1.0            0.559          0.559            3562.019782\n\nQA Optimization Comparison completed successfully!\nCheck your WandB dashboard for detailed metrics and visualizations.\n","output_type":"stream"}],"execution_count":27}]}